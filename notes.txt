Vulkan sdk
location
/etc/vulkan/icd.d/ or /usr/share/vulkan/icd.d 	Vulkan driver JSON manifest file, which is not modified by the SDK installer.

GLSLC
Location: /usr/local/bin/glslc
Does not recognise .vs and .fs. But recognized .vs .fs

Vulkan usa muito typedef para facilitar o gerenciamento dos dados pois os typedef ja definem como os objects serao formatados.

In game engines/development, its a good option to go for ECS over Object Oriented (inheritance). ECS stands for Entity component system.
Its focused on association over inheritance. Like, entities having behavior being applied to an entity (a game object) by a component.
https://www.kodeco.com/2806-introduction-to-component-based-architecture-in-games



In tutorial, device, pipeline, window and maybe other artifacts are called lve_filename.ext. Ex: lve_window.cpp.
I'm removing its prefix to be generic, but applied them to classes. But instead of lve, i'm using uffdejavu for namespace and UD for 
classes prefix.

In vulkan, it happens many times that instead of calling many parameters, we create a struct and refer to its pointer.

Required extensions are defined by glfw to display content

Vulkan's Canonical ViewVolume(VCVV): Only what is inside this region is displayed. The Canonical view volume
goes through a viewport transformation to appear on the viewport (screen view)

X from (-1, 1)
Y from (-1, 1)
Z from (0, 1)
6 planes, (l)eft, (r)ight, (t)op, (b)ottom, (n)ear and (f)ar planes.

Positive X points right
Positive Y points down
Positive Z points into the screen

How to make VCVV into a ortographic view
1- Translate center c of the box so that the center of the near plane is at the origin.
c = ((r+l)/2, (b+t)/2, n)
Translation matrix:
| 1   0   0   -(r+l)/2 |
| 0   1   0   -(b+t)/2 |
| 0   0   1       -n   |
| 0   0   0       1    |


2- Scale the matrix so that the box have the same value in all dimensions, 
Numerator will be the canonical volume dimentions and the denominator will be the dimensions 
of the orthographic view volume
Scale matrix:
| 2/(r-l)     0        0        0|
|   0      2/(b-t)     0        0|
|   0         0      1/(f-n)    0|
|   0         0        0        0|

So, the ortographic matrix will be Scale X Translation (VCVV and Coordinate system differs from opengl, etc)

| 2/(r-l)     0        0        -(r+l)/(r-l) |
|   0      2/(b-t)     0        -(b+t)/(b-t) |
|   0         0      1/(f-n)        -n/(f-n) |
|   0         0        0              1      |


Perspective matrix: Needs Homogeneous coordinates to make  nx/z and ny/z to work (explanation on video 12 of tutorial)
Perpective Matrix ?
  ? X (times)     x     nx/z   
                  y     ny/z   
                  z =     ?      
                  1       

Homogeneous Vector <=> Position vector 

X           X/W
Y     <=>   Y/W
Z           Z/W
W
 
vectors:
                            position
1         10    =    2    =    1          
2         20    =    4    =    2
3     =   30    =    6    =    3      
1         10    =    2    =    

This division by W is always applied to gl_Position from vertex shader.
If we change that last parameter from 1.0 to 2.0, the objects will appear the half of the size

So, now we can represent the result as 
nx   
ny   
?    
Z     


      ?                          
n   0   0   0       x          nx           
0   n   0   0   X   y     =    ny           
0   0   ?   ?       z          ?  
0   0   1   0       1          Z  

2,2 cant be z, because the result in z where Z/Z = 1 will make us lose our depth
So we need our solution Z to be Z^2 because the solution Z^2/Z = Z

n   0   0   0       x          nx           
0   n   0   0   X   y     =    ny           
0   0   m1  m2      z          Z^2  
0   0   1   0       1          Z  


m1Z + m2 = Z^2
for z=n, z=f Equacao normal de segundo grau, com Z quadratico, pode ter ate 2 solucoes
  nx
  ny
m1z+m2 
  Z 

This means that the transformation will not change the values of points in the Near and Far planes.
But all other Z values will be warped (perspective.) Manero.

1- m1n + m2 = n^2
2- m1f + m2 = f^2

m1 = f + n
m2 = -fn

n       0       0       0           x          nx 
0       n       0       0     X     y     =    ny 
0       0       (f+n)  -fn          z          (f+n)z - fn
0       0       1       0           1          Z  



perspective projection matrix   =  ortographic projection matrix  *   perspective matrix

|2n      0       -(r+l)/(r-l)    0      |       | 2/(r-l)     0      0       -(r+l)/(r-l) |  X | n   0     0     0 |     
|0     2n/(b-t)  -(b+t)/(b-t)    0      |      =|   0       2/(b-t)  0       -(b+t)/(b-t) |  X | 0   n     0     0 |            
|0       0          f/(f-n)    -fn/(f-n)|       |   0         0     1/(f-n)      -n/(f-n) |  X | 0   0   (f+n) -fn |    
|0       0             1         0      |       |   0         0      0             0      |  X | 0   0     1     0 |

In order to simplify: Assuming frustum is centered on the z-axis
r = -l
t = -b
then r+l=0, r-l = 2r  and   b+t=0, b-t=2b

|n/r     0      0        0      |
|0      n/b     0        0      |
|0       0    f/(f-n)  -fn/(f-n)|
|0       0      1        0      |

Aspec Ratio = W/H (of screen, fustrum plane)
near right bottom corner (r,b,n)
b=n*tan(theta/2), r=n*(w/h)*tan(theta/2)

By this, the perspective matrix for vulkan is

|1/((w/h)tan(theta/2))    0                 0        0      |
|0                        1/tan(theta/2)    0        0      |
|0                        0               f/(f-n)  -fn/(f-n)|
|0                        0                 1        0      |

By some explanation, near values have higher quality than far values. O intuitivo, mas a explicacao foi feita matematicamente.


Vertex buffeR: Armazena os vertices (x,y,z, ... values)
Index buffer: organiza os vertices do index buffer indexados de forma a saber quais indices formam triangulos
ex:
vertex buffer {v0, v1, v2, v3, v4...}
index buffer {0, 1, 2, 2, 1, 3, 0}....
                1tr       2tr    ...  // indices 0, 1, 2 (que sao vertices) compoem o primeiro triangulo, ...





Swap chain: Is a series of framebuffers used to dfiplay images to the window. Modern OSs usually have at least 2 buffers
at once (double buffering). The frontbuffer and backbuffer. Pipeline renders data to the backbuffer, and when ready, 
the swap chain handles coordinating with the display prior to vertical sync. When swapped, while backbuffer is being displayed,
the gpu pipeline will output the data into tha frontbuffer. 
They are basically equal and swapped to display the data.

Tearing: Seeing data from multiple frames at once.

We will work with multiple framebuffers (2 or 3)
We can use swapChain.acquireNextImage() to get the next index of our framebuffers


Sure, in the context of Vulkan, passes and subpasses are related to the concept of Render Passes.

**Render Passes** in Vulkan represent a collection of graphics rendering operations that are related to each other. 
The operations are grouped together because they are expected to be executed sequentially. 
A render pass in Vulkan describes the format of the framebuffers, the number of color and depth buffers, 
the samples used for each buffer, and what to do with the data in the buffers throughout rendering operations.
**Subpasses** are a part of a render pass. They represent a single rendering operation within the larger render pass. Subpasses can depend on each other, meaning the output of one subpass can be used as input to another subpass. This allows for efficient hardware utilization as the output of one subpass can be directly used by another subpass without having to write it to memory and then read it back.

For example, in a deferred shading pipeline, you might have one subpass that writes to a G-buffer, and a second subpass that reads from the G-buffer to perform lighting calculations. By using subpasses, Vulkan can optimize this so that the G-buffer data doesn't need to be written out to memory and then read back in between the two subpasses.

**Passes** in this context usually refer to the entire render pass, which includes all of its subpasses.

In summary, render passes and subpasses are a way for you to tell Vulkan about the dependencies between different rendering operations, which allows Vulkan to optimize the execution of these operations for better performance.

Ao trocar dados entre shaders, o layout tem que ser o mesmo entre quem envia e quem recebe. O nome das variaveis nao precisa ser igual3

--
Linear Interpolation (L. I.)
P = a(1-t) + bt  --// If multi dimensional, Px = ax(1-t) + bt and so on.
Where a is a and b are points with absolute known values. 
t is the interpolation point proximity that lies between a and b. Where t = [0,1]

L. I. between many points: Barycentric coordinates.

3 points a, b and c
What is the interpolated value of a point P inside this triangle?
P = b*Beta + c*Gamma + a(1-Beta-Gama) (weights of b and c); Alpha = 1 - Beta - Gamma
then P = a*Alpha + b*Beta = c*Gamma ; Alpha + Beta + Gamma = 1 (constraint). Alpha, Beta and Gamma MUST be (0, 1)

assert vs if
If deals with pathes in the code, the decision conditions.
Assert is used when you expect only 1 behavior and the assertion should be a big exception (therefore, possibly error handling to some point)

** Estudar depois com mais calma: Coordandas homogeneas. Para melhor desenvolver questoes de translacao e transformacoes



--Codigo do siepisnki triangle

void FirstApp::sierpinski(
    std::vector<LveModel::Vertex> &vertices,
    int depth,
    glm::vec2 left,
    glm::vec2 right,
    glm::vec2 top) {
  if (depth <= 0) {
    vertices.push_back({top});
    vertices.push_back({right});
    vertices.push_back({left});
  } else {
    auto leftTop = 0.5f * (left + top);
    auto rightTop = 0.5f * (right + top);
    auto leftRight = 0.5f * (left + right);
    sierpinski(vertices, depth - 1, left, leftRight, leftTop);
    sierpinski(vertices, depth - 1, leftRight, right, rightTop);
    sierpinski(vertices, depth - 1, leftTop, rightTop, top);
  }
}
void FirstApp::loadModels() {
  std::vector<LveModel::Vertex> vertices{};
  sierpinski(vertices, 5, {-0.5f, 0.5f}, {0.5f, 0.5f}, {0.0f, -0.5f});
  lveModel = std::make_unique<LveModel>(lveDevice, vertices);
}